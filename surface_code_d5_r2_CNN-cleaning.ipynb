{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:03:22.551154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pymatching\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from circuit_generators import *\n",
    "from sampling_functions import *\n",
    "from bitpack import pack_bits, unpack_bits\n",
    "from circuit_partition import *\n",
    "from utilities_tf import *\n",
    "from CNNModel import *\n",
    "\n",
    "\n",
    "# Number of worker nodes\n",
    "n_worker_nodes = 8\n",
    "\n",
    "# Surface code specifications\n",
    "d = 5\n",
    "r = 2\n",
    "kernel_size = 3\n",
    "\n",
    "# Error probabilities\n",
    "p = 0.01\n",
    "before_round_data_depolarization = p\n",
    "after_reset_flip_probability = p\n",
    "after_clifford_depolarization = p\n",
    "before_measure_flip_probability = p\n",
    "\n",
    "use_rotated_z = True\n",
    "observable_type = \"ZL\" if use_rotated_z else \"XL\"\n",
    "\n",
    "# Bit types\n",
    "binary_t = np.int8 # Could use even less if numpy allowed\n",
    "\n",
    "# Measurement index type\n",
    "idx_t = np.int8\n",
    "n_all_measurements = r*(d**2-1) + d**2\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int16\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int32\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int64\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int128\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int256\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  raise RuntimeError(\"idx_t is too small.\")\n",
    "\n",
    "# Call signature for circuit_partition::group_det_bits_kxk\n",
    "call_group_det_bits_kxk = lambda det_bits_dxd, data_bits_dxd=None, d=d, r=r, k=kernel_size, use_rotated_z=use_rotated_z, binary_t=binary_t, idx_t=idx_t: group_det_bits_kxk(det_bits_dxd, d, r, k, use_rotated_z, data_bits_dxd, binary_t, idx_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average flip rate for the full circuit: 0.2298373\n"
     ]
    }
   ],
   "source": [
    "n_test = 5000000\n",
    "n_train = 5000000\n",
    "n_samples = n_test + n_train\n",
    "decoders = ['pymatching']\n",
    "test_circuit = get_builtin_circuit(\n",
    "  \"surface_code:rotated_memory_\"+('z' if use_rotated_z else 'x'),\n",
    "  distance=d,\n",
    "  rounds=r,\n",
    "  before_round_data_depolarization = before_round_data_depolarization,\n",
    "  after_reset_flip_probability = after_reset_flip_probability,\n",
    "  after_clifford_depolarization = after_clifford_depolarization,\n",
    "  before_measure_flip_probability = before_measure_flip_probability\n",
    ")\n",
    "\n",
    "kernel_circuit_extra_depol1 = [\n",
    "  [\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 13 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 5 13 17 19 25\",\n",
    "    f\"#DEPOLARIZE1({after_clifford_depolarization})\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 12 15 19\",\n",
    "  ], # parity = (1, 1)\n",
    "  [\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 8 13 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 5 13 17 19 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 1 14 15\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 12 14 15 19\",\n",
    "  ], # parity = (0, 1)\n",
    "  [\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 8 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 17 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 1 14 15\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 14 15\",\n",
    "  ], # parity = (-1, 1)\n",
    "  [\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 5 13 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 5 13 17 19 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 2 3\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 2 12 15 19\",\n",
    "  ], # parity = (1, 0)\n",
    "  [\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 1 5 8 13 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 5 13 17 19 25\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 1 2 3 14 15\",\n",
    "    f\"DEPOLARIZE1({after_clifford_depolarization}) 2 12 14 15 19\",\n",
    "  ] # parity = (0, 0)\n",
    "]\n",
    "kernel_circuits = []\n",
    "for replace_args in kernel_circuit_extra_depol1:\n",
    "  kernel_circuit_template = \\\n",
    "  f\"\"\"\n",
    "QUBIT_COORDS(1, 1) 1\n",
    "QUBIT_COORDS(2, 0) 2\n",
    "QUBIT_COORDS(3, 1) 3\n",
    "QUBIT_COORDS(5, 1) 5\n",
    "QUBIT_COORDS(1, 3) 8\n",
    "QUBIT_COORDS(2, 2) 9\n",
    "QUBIT_COORDS(3, 3) 10\n",
    "QUBIT_COORDS(4, 2) 11\n",
    "QUBIT_COORDS(5, 3) 12\n",
    "QUBIT_COORDS(6, 2) 13\n",
    "QUBIT_COORDS(0, 4) 14\n",
    "QUBIT_COORDS(1, 5) 15\n",
    "QUBIT_COORDS(2, 4) 16\n",
    "QUBIT_COORDS(3, 5) 17\n",
    "QUBIT_COORDS(4, 4) 18\n",
    "QUBIT_COORDS(5, 5) 19\n",
    "QUBIT_COORDS(4, 6) 25\n",
    "R 1 3 5 8 10 12 15 17 19\n",
    "X_ERROR({after_reset_flip_probability}) 1 3 5 8 10 12 15 17 19\n",
    "R 2 9 11 13 14 16 18 25\n",
    "X_ERROR({after_reset_flip_probability}) 2 9 11 13 14 16 18 25\n",
    "TICK\n",
    "DEPOLARIZE1({before_round_data_depolarization}) 1 3 5 8 10 12 15 17 19\n",
    "H 2 11 16 25\n",
    "DEPOLARIZE1({after_clifford_depolarization}) 2 11 16 25\n",
    "TICK\n",
    "CX 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "DEPOLARIZE2({after_clifford_depolarization}) 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "{replace_args[0]}\n",
    "TICK\n",
    "CX 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "DEPOLARIZE2({after_clifford_depolarization}) 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "{replace_args[1]}\n",
    "TICK\n",
    "CX 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "DEPOLARIZE2({after_clifford_depolarization}) 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "{replace_args[2]}\n",
    "TICK\n",
    "CX 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "DEPOLARIZE2({after_clifford_depolarization}) 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "{replace_args[3]}\n",
    "TICK\n",
    "H 2 11 16 25\n",
    "DEPOLARIZE1({after_clifford_depolarization}) 2 11 16 25\n",
    "TICK\n",
    "X_ERROR({before_measure_flip_probability}) 2 9 11 13 14 16 18 25\n",
    "MR 2 9 11 13 14 16 18 25\n",
    "X_ERROR({after_reset_flip_probability}) 2 9 11 13 14 16 18 25\n",
    "DETECTOR(0, 4, 0) rec[-4]\n",
    "DETECTOR(2, 2, 0) rec[-7]\n",
    "DETECTOR(4, 4, 0) rec[-2]\n",
    "DETECTOR(6, 2, 0) rec[-5]\n",
    "REPEAT {r-1} {{\n",
    "  TICK\n",
    "  DEPOLARIZE1({before_round_data_depolarization}) 1 3 5 8 10 12 15 17 19\n",
    "  H 2 11 16 25\n",
    "  DEPOLARIZE1({after_clifford_depolarization}) 2 11 16 25\n",
    "  TICK\n",
    "  CX 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "  DEPOLARIZE2({after_clifford_depolarization}) 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "  {replace_args[0]}\n",
    "  TICK\n",
    "  CX 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "  DEPOLARIZE2({after_clifford_depolarization}) 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "  {replace_args[1]}\n",
    "  TICK\n",
    "  CX 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "  DEPOLARIZE2({after_clifford_depolarization}) 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "  {replace_args[2]}\n",
    "  TICK\n",
    "  CX 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "  DEPOLARIZE2({after_clifford_depolarization}) 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "  {replace_args[3]}\n",
    "  TICK\n",
    "  H 2 11 16 25\n",
    "  DEPOLARIZE1({after_clifford_depolarization}) 2 11 16 25\n",
    "  TICK\n",
    "  X_ERROR({before_measure_flip_probability}) 2 9 11 13 14 16 18 25\n",
    "  MR 2 9 11 13 14 16 18 25\n",
    "  X_ERROR({after_reset_flip_probability}) 2 9 11 13 14 16 18 25\n",
    "  SHIFT_COORDS(0, 0, 1)\n",
    "  DETECTOR(2, 0, 0) rec[-8] rec[-16]\n",
    "  DETECTOR(2, 2, 0) rec[-7] rec[-15]\n",
    "  DETECTOR(4, 2, 0) rec[-6] rec[-14]\n",
    "  DETECTOR(6, 2, 0) rec[-5] rec[-13]\n",
    "  DETECTOR(0, 4, 0) rec[-4] rec[-12]\n",
    "  DETECTOR(2, 4, 0) rec[-3] rec[-11]\n",
    "  DETECTOR(4, 4, 0) rec[-2] rec[-10]\n",
    "  DETECTOR(4, 6, 0) rec[-1] rec[-9]\n",
    "}}\n",
    "X_ERROR({before_measure_flip_probability}) 1 3 5 8 10 12 15 17 19\n",
    "M 1 3 5 8 10 12 15 17 19\n",
    "DETECTOR(0, 4, 1) rec[-3] rec[-6] rec[-13]\n",
    "DETECTOR(2, 2, 1) rec[-5] rec[-6] rec[-8] rec[-9] rec[-16]\n",
    "DETECTOR(4, 4, 1) rec[-1] rec[-2] rec[-4] rec[-5] rec[-11]\n",
    "DETECTOR(6, 2, 1) rec[-4] rec[-7] rec[-14]\n",
    "OBSERVABLE_INCLUDE(0) rec[-7] rec[-8] rec[-9]\n",
    "  \"\"\"\n",
    "  kernel_circuits.append(stim.Circuit(kernel_circuit_template))\n",
    "\n",
    "\n",
    "# Sampling for the dxd circuit\n",
    "m_sampler = test_circuit.compile_sampler(seed=12345)\n",
    "converter = test_circuit.compile_m2d_converter()\n",
    "detector_error_model = test_circuit.detector_error_model(decompose_errors=True)\n",
    "\n",
    "measurements = m_sampler.sample(n_samples, bit_packed=False)\n",
    "det_evts, flips = converter.convert(measurements=measurements, separate_observables=True, bit_packed=False)\n",
    "measurements = measurements.astype(binary_t)\n",
    "det_evts = det_evts.astype(binary_t)\n",
    "flips = flips.astype(binary_t)\n",
    "\n",
    "avg_flips = np.sum(flips.reshape(-1,), dtype=np.float32)/flips.shape[0]\n",
    "print(f\"Average flip rate for the full circuit: {avg_flips}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [1 0 0 1 0]\n",
      " ...\n",
      " [1 1 0 1 1]\n",
      " [0 0 1 0 1]\n",
      " [0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def split_measurements(measurements, d):\n",
    "  n_measurements = idx_t(measurements.shape[1])\n",
    "  # Measurements on data qubits come last\n",
    "  exclude_indices = np.array([-x-1 for x in range(d**2)], dtype=idx_t)\n",
    "  exclude_indices = exclude_indices + n_measurements\n",
    "  # Out of all measurements on data qubits, the logical qubit measurements are those on the boundary of the lattice.\n",
    "  # All other equivalent X_L/Z_L operators can be found through the combination of ancilla measurements and the chosen data qubits giving us the logical qubit.\n",
    "  exclude_indices_obsL = np.array([-x-1 for x in range(d*(d-1), d**2)], dtype=idx_t)\n",
    "  exclude_indices_obsL = exclude_indices_obsL + n_measurements\n",
    "  # From obs_bits, we want to exclude all measurements except those listed in exclude_indices_obsL\n",
    "  exclude_indices_obs = np.arange(0, n_measurements, 1, dtype=idx_t)\n",
    "  exclude_indices_obs = np.delete(exclude_indices_obs, exclude_indices_obsL)\n",
    "\n",
    "  det_bits = measurements\n",
    "  det_bits = np.delete(det_bits, exclude_indices, axis=1)\n",
    "  obs_bits = measurements\n",
    "  obs_bits = np.delete(obs_bits, exclude_indices_obs, axis=1)\n",
    "\n",
    "  data_bits = measurements[:, exclude_indices]\n",
    "\n",
    "  # Reverse the order of data_bits because exclude_indices starts from the last data qubit measurement, not the first\n",
    "  data_bits = np.flip(data_bits, axis=1)\n",
    "\n",
    "  return det_bits, obs_bits, data_bits\n",
    "\n",
    "\n",
    "n_measurements = idx_t(measurements.shape[1])\n",
    "det_bits, obs_bits, data_bits = split_measurements(measurements, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 10000000, 16)\n",
      "(9, 10000000, 9)\n",
      "(9, 10000000, 3)\n",
      "(3, 10000000, 2)\n",
      "[0]\n",
      "[1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0]\n",
      "[0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 1]\n",
      "[[[1, 1], [0, 8]], [[0, 1], [1, 7]], [[-1, 1], [2, 6]], [[1, 0], [3, 5]], [[0, 0], [4]]]\n",
      "[1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 1 1 0 1]\n",
      "[0 1 0]\n",
      "[0 0]\n",
      "[1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0]\n",
      "[1 0 1 0 1 0 0 1 0]\n",
      "[1 0 1]\n",
      "[1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1]\n",
      "[0 1 0 1 0 0 1 0 0]\n",
      "[0 1 0]\n",
      "[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "[0 1 1 1 0 1 1 0 1]\n",
      "[1 1 0]\n",
      "[0 0]\n",
      "[1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 1 0 0 1 0 1 1 0]\n",
      "[0 1 0]\n",
      "[1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0]\n",
      "[0 0 1 0 0 1 0 0 1]\n",
      "[1 0 0]\n",
      "[1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[1 1 0 1 1 0 1 0 1]\n",
      "[0 1 1]\n",
      "[0 0]\n",
      "[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "[1 1 1 1 1 0 0 1 0]\n",
      "[1 1 1]\n",
      "[0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1]\n",
      "[1 1 1 0 0 1 0 0 1]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "det_bits_kxk_all, data_bits_kxk_all, obs_bits_kxk_all, kernel_result_translation_map = call_group_det_bits_kxk(det_bits, data_bits_dxd=data_bits)\n",
    "\n",
    "\n",
    "kernel_types = get_unique_kernel_types(kernel_size, d)\n",
    "n_kernels = det_bits_kxk_all.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10000000, 1)\n",
      "(3, 10000000, 1)\n",
      "(3, 10000000, 1)\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "kernel_result_translation_map_f = kernel_result_translation_map[:,:,1:]\n",
    "kernel_result_translation_map_b = kernel_result_translation_map[:,:,0:-1]\n",
    "kernel_result_translation_det_evts = (kernel_result_translation_map_f!=kernel_result_translation_map_b).astype(binary_t)\n",
    "kernel_result_translation_map = np.concatenate((kernel_result_translation_map, kernel_result_translation_det_evts), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 10000000, 16)\n",
      "(9, 10000000, 1)\n"
     ]
    }
   ],
   "source": [
    "det_evts_kxk_all = []\n",
    "flips_kxk_all = []\n",
    "converters_kernel = []\n",
    "for kernel_circuit in kernel_circuits:\n",
    "  converters_kernel.append(kernel_circuit.compile_m2d_converter())\n",
    "for k in range(n_kernels):\n",
    "  measurements_kxk = np.concatenate((det_bits_kxk_all[k], data_bits_kxk_all[k]), axis=1).astype(np.bool_)\n",
    "  ik = 0\n",
    "  for i, kernel_type in enumerate(kernel_types):\n",
    "    if k in kernel_type[1]:\n",
    "      ik = i\n",
    "      break\n",
    "  det_evts_kxk, flips_kxk = converters_kernel[ik].convert(measurements=measurements_kxk, separate_observables=True, bit_packed=False)\n",
    "  det_evts_kxk_all.append(det_evts_kxk)\n",
    "  flips_kxk_all.append(flips_kxk)\n",
    "det_evts_kxk_all = np.array(det_evts_kxk_all, dtype=binary_t)\n",
    "flips_kxk_all = np.array(flips_kxk_all, dtype=binary_t)\n",
    "del converters_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 9, 16)\n",
      "(10000000, 9, 16)\n",
      "(10000000, 9)\n",
      "(10000000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Make sure the data type is np.int32 below, not idx_t!\n",
    "idxs_test, idxs_train = split_data(np.arange(n_samples, dtype=np.int32), test_size = n_test/n_samples, seed = 12345, shuffle = False)\n",
    "\n",
    "class_bits = flips\n",
    "features_det_bits = np.swapaxes(det_bits_kxk_all, 0, 1)\n",
    "features_det_evts = np.swapaxes(det_evts_kxk_all, 0, 1)\n",
    "features_translation_map = np.swapaxes(kernel_result_translation_map, 0, 1) # Dimensions go as [sample][kernel][cycle bits + detections (n_cycles-1)]\n",
    "features_translation_map = np.reshape(features_translation_map, (features_translation_map.shape[0], -1))\n",
    "features_final_det_evts = det_evts[:, -((d**2-1)//2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  elif epoch < 20:\n",
    "    return lr * 0.9\n",
    "  elif epoch < 30:\n",
    "    return lr * 0.8\n",
    "  else:\n",
    "    return lr * 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique contributions: 13\n",
      "Total number of fractions: 28\n",
      "Total number of phases: 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"full_cnn_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"full_cnn_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_kernel (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CNNKernel</span>)          │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CNNKernel</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CNNKernel</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CNNKernel</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CNNKernel</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,070</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_kernel (\u001b[38;5;33mCNNKernel\u001b[0m)          │ ?                      │         \u001b[38;5;34m1,926\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_1 (\u001b[38;5;33mCNNKernel\u001b[0m)        │ ?                      │         \u001b[38;5;34m1,926\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_2 (\u001b[38;5;33mCNNKernel\u001b[0m)        │ ?                      │         \u001b[38;5;34m1,926\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_3 (\u001b[38;5;33mCNNKernel\u001b[0m)        │ ?                      │         \u001b[38;5;34m1,926\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_kernel_4 (\u001b[38;5;33mCNNKernel\u001b[0m)        │ ?                      │         \u001b[38;5;34m1,070\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │         \u001b[38;5;34m2,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │         \u001b[38;5;34m2,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m101\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,765</span> (92.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,765\u001b[0m (92.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,765</span> (92.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,765\u001b[0m (92.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:04:23.479038: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 576000000 exceeds 10% of free system memory.\n",
      "2024-06-11 13:04:25.617570: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 576000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8008 - loss: 0.4148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:06:00.167842: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 144000000 exceeds 10% of free system memory.\n",
      "2024-06-11 13:06:00.649553: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 144000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 235ms/step - accuracy: 0.8009 - loss: 0.4145 - val_accuracy: 0.9208 - val_loss: 0.1902 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 212ms/step - accuracy: 0.9302 - loss: 0.1699 - val_accuracy: 0.9448 - val_loss: 0.1393 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 208ms/step - accuracy: 0.9475 - loss: 0.1331 - val_accuracy: 0.9506 - val_loss: 0.1249 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 205ms/step - accuracy: 0.9525 - loss: 0.1208 - val_accuracy: 0.9546 - val_loss: 0.1161 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 206ms/step - accuracy: 0.9553 - loss: 0.1138 - val_accuracy: 0.9564 - val_loss: 0.1117 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:11:54.001407: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 720000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 142ms/step\n",
      "Inaccuracy of the final model on the test data: 0.0433472\n"
     ]
    }
   ],
   "source": [
    "for n_nodes in range(100, 150, 50):\n",
    "  model_dxd = FullCNNModel(\n",
    "    observable_type, d, kernel_size, r,\n",
    "    [n_nodes for _ in range(2)],\n",
    "    npol=2,\n",
    "    do_all_data_qubits=False, extended_kernel_output=True, include_det_evts=True,\n",
    "    include_last_kernel_dets=False, include_last_dets=True, has_nonuniform_response=False, use_translated_kernels=False\n",
    "  )\n",
    "  model_dxd.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model_dxd([ features_det_bits[0:1], features_det_evts[0:1], features_translation_map[0:1], features_final_det_evts[0:1] ])\n",
    "  model_dxd.summary()\n",
    "\n",
    "  val_split = 0.2\n",
    "  n_epochs = 5 # 50\n",
    "  history = model_dxd.fit(\n",
    "    x=[ features_det_bits[idxs_train], features_det_evts[idxs_train], features_translation_map[idxs_train], features_final_det_evts[idxs_train] ],\n",
    "    y=class_bits[idxs_train,:],\n",
    "    batch_size=10000,\n",
    "    epochs=n_epochs, validation_split=val_split,\n",
    "    callbacks=[\n",
    "      tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "      tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  flips_pred = model_dxd.predict(\n",
    "    [features_det_bits[idxs_test], features_det_evts[idxs_test], features_translation_map[idxs_test], features_final_det_evts[idxs_test]],\n",
    "    batch_size=10000\n",
    "  )\n",
    "  print(f\"Inaccuracy of the final model on the test data: {(flips[idxs_test]!=(flips_pred>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMatching error rate for the full data set: 0.0315598\n",
      "PyMatching error rate for test data set: 0.031606\n"
     ]
    }
   ],
   "source": [
    "pymatcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "flips_pred_pym = pymatcher.decode_batch(det_evts, bit_packed_predictions=False, bit_packed_shots=False).astype(binary_t).reshape(-1,1)\n",
    "print(f\"PyMatching error rate for the full data set: {np.sum((flips_pred_pym!=flips))/flips_pred_pym.shape[0]}\")\n",
    "flips_pred_pym = pymatcher.decode_batch(det_evts[idxs_test,:], bit_packed_predictions=False, bit_packed_shots=False).astype(binary_t).reshape(-1,1)\n",
    "print(f\"PyMatching error rate for test data set: {np.sum((flips_pred_pym!=flips[idxs_test,:]))/flips_pred_pym.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
